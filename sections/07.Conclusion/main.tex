%!TEX root = ../../main.tex
\chapter{まとめ}
%--------%---------%---------%--------%---------%---------
\section{本研究の要約}
本研究では直感的にリズムと旋律線を入力すれば背景楽曲との調性を満たす音を出力する演奏インタフェースを実現した．リズムと旋律線はRealSenseカメラを利用して入力し，ジェスチャー認識機能によってインタフェースの操作を行う．RealSense SDKのジェスチャー認識機能には認識漏れや，遅延などが目立ったため，本研究では指先や手のひらの速度や移動距離の閾値，指の開閉度などのパラメータを利用してジェスチャーの認識精度を向上させた．また，深度と身体動作から演奏中に発音可能な音高の範囲を指定できる機能を追加して演奏の自由度をあげた．出力される音はあらかじめSongleから統計的に生成した背景楽曲との調性制約によって決定し，発音可能な周波数列をコード進行に応じて変化させる．特に認識漏れや遅延の多いtap認識の改善と生成した調性制約について，評価実験を行ったところ，改善したtap認識機能はRealSense SDKと比べ実用的な精度であり，調性制約はコードの構成音のみを周波数列とする調性制約より不協和音が多いがわずかに意図通りの演奏がしやすいという評価を得た．
\section{今後の展望}
今後の課題・展望としては機能面において，音量変更機能や，楽器音の出力機能の実装や調性制約の精度向上．マウス，タブレットなどを入力装置とした本システムの実装．ハッカソンなどで簡単に扱えるようAPI化など，他の入力装置への対応や連携の充実化を図りたい．
将来的には，地域社会振興のために開催される音楽イベント，アーティストのコンサートなど多人数で同時に即興合奏ができるように，複数人の身体動作入力の処理，画面を見ないでも操作できるような直感的な操作，オンラインで離れた人と合奏などを今後の課題としたい．
